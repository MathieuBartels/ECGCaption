{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import torch\n",
    "import collections\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "import tqdm\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "from ecgnet.utils.transforms import ToTensor, ApplyGain, Resample\n",
    "\n",
    "from EcgCaptionGenerator.utils.dataset import collate_fn, CaptionDataset\n",
    "from EcgCaptionGenerator.utils.pycocoevalcap.eval import COCOEvalCap\n",
    "\n",
    "\n",
    "from EcgCaptionGenerator.systems.top_down_attention_lstm import TopDownLSTM\n",
    "\n",
    "from EcgCaptionGenerator.systems.topic_unchanged_decoder import TopicSimDecoder\n",
    "from EcgCaptionGenerator.systems.topic_transformer import TopicTransformer\n",
    "\n",
    "from EcgCaptionGenerator.systems.transformer import Transformer\n",
    "from EcgCaptionGenerator.util import get_loaders, get_loaders_toy_data, FakeDataset\n",
    "from EcgCaptionGenerator.network.utils_model import beam_search\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = './training/captioning/models/'\n",
    "\n",
    "use_topic_model = True\n",
    "\n",
    "# checkpoint_loc, use_topic, param_file = basedir + 'topic/TOP-68/checkpoints/epoch=10-step=45594.ckpt', True, 'config_topic_physician_corrected.json' # Muse 4.3\n",
    "checkpoint_loc, use_topic, param_file = basedir + 'topic/TOP-74/checkpoints/epoch=12-step=10009.ckpt', True, 'config_topic_physician_annotated.json' # consults 28\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.seed_everything(1234)\n",
    "params = json.load(open(param_file, 'r'))\n",
    "\n",
    "transform = transforms.Compose([Resample(500), ToTensor(), ApplyGain()])\n",
    "\n",
    "model = TopicSimDecoder.load_from_checkpoint(checkpoint_path=checkpoint_loc).cuda()\n",
    "\n",
    "threshold, is_train, vocab = 0, False, model.vocab\n",
    "\n",
    "testset_df = pd.read_csv(params['test_labels_csv'], index_col=0)\n",
    "testset = FakeDataset(100, use_topic, vocab, transform=transform)\n",
    "\n",
    "gts = testset_df.apply(lambda x: {x['TestID']: [x['Label']]}, axis=1).to_list()\n",
    "gts = {list(dict_item.keys())[0]: list(dict_item.values())[0][0] for dict_item in gts}\n",
    "test_loader = DataLoader(testset, batch_size=64,\n",
    "                            num_workers=4, collate_fn=collate_fn)\n",
    "# max_length=50\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = {'temp':None, 'k':None, 'p':None, 'greedy':True, 'm':None}\n",
    "gts = {}\n",
    "res = {}\n",
    "for batch_idx, batch in enumerate(tqdm.tqdm(test_loader)):\n",
    "    waveforms, _, _, ids, targets, _, topic = batch\n",
    "    tags, (words, props) = model.sample(waveforms.cuda(), ids, s)\n",
    "    truth = model.vocab.decode(targets)\n",
    "    for i in range(waveforms.shape[0]):\n",
    "        gts[ids[i]] = [truth[i]]\n",
    "        res.update(words)\n",
    "\n",
    "\n",
    "gts = collections.OrderedDict(sorted(gts.items()))\n",
    "res = collections.OrderedDict(sorted(res.items()))\n",
    "\n",
    "pd.DataFrame(gts).to_csv(checkpoint_loc[:-5] + 'gts_.csv')\n",
    "pd.DataFrame(res).to_csv(checkpoint_loc[:-5] + 'res_.csv')\n",
    "\n",
    "COCOEval = COCOEvalCap()\n",
    "COCOEval.evaluate(gts, res)\n",
    "print(s, COCOEval.eval)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
